---
title: Engineering and Craft
publishedAt: '2022-05-17'
lastUpdated: ''
summary: 'On having standards, building things and writing code for fun and profit.'
tags: ['career', 'reflections', 'serverless']
---

I'd like to be a software engineer, although I struggle with the term.

It's very difficult to think of myself or many of my newly found peers
in the software industry as engineers. Writing code often feels like
an adventure: only sometimes do I have a faint clue what I'm doing
or where I'm going.

Looking around, it seems like I'm not alone: things break on a regular basis
everywhere, from smart lights to airplane controls to elevators.
Lines of code glitch and fall apart mid-process, sometimes with terrible consequences.
We've come to expect it.

I'm just happy that when my experiments fail, nobody gets buried in a pile of rubble.

### Yeah, but what do you know about anything?

Fair, I'm new to this. I [started](/blog/switching-lanes) coding barely two years ago and
have been doing so professionally just over a year. So here's someone significantly more
experienced than me:

> We should recognize and accept that our discipline is a creative design discipline
> and has no meaningful relationship to production-engineering and instead focus on
> mastery of the skills of exploration, discovery, and learning.

<small>David Farley, Modern Software Engineering</small>

That's [Dave Farley](https://twitter.com/davefarley77),
in a [recent book](https://www.davefarley.net/?p=352) of his, on the topic of software engineering.
He's an old-school professional whose thoughts are worth a ponder.

### Titles and credentialism

The word engineering implies a fairly rigorous process and a high bar of competence.
Not all who program are engineers in this sense.

Titles in the software industry seem to most reliably indicate salary, rather than difficulty of
the task or burden of responsibility. The success of software startups is more about stumbling
into a market than building quality software.

> "Software engineers/data scientists are paid more because
> we have to study more to keep up to date with this fast-moving industry
> that changes more than any other field."

> Sorry, but this is false: both that we need to study more,
> or that this is the reason.

<small>
  [Gergely Orosz](https://twitter.com/GergelyOrosz/status/1523991858728292355) in a tweet
  on May 10, 2022
</small>

Electrical engineers or construction engineers accept liability when things go wrong.
By signing off on a document, an engineer takes personal and professional responsibility
for the accuracy of their best effort. It's more than credentialism, at least that part of it.

In software, a seal of quality accompanied by such responsibility seems rare.

[Margaret Hamilton](https://www.smithsonianmag.com/smithsonian-institution/margaret-hamilton-led-nasa-software-team-landed-astronauts-moon-180971575/)
was a software engineer. That's the standard.

Should developers calling themselves engineers make more of an effort to earn the title?
If so, what would that effort look like and what are the metrics?

### What to measure?

Work done by Nicole Fosgren, Jez Humble, and Gene Kim in the "[State of DevOps](https://cloud.google.com/devops/)"
reports and their book [Accelerate](https://itrevolution.com/book/accelerate/) suggests that better outcomes
can be reached by focusing on two measures: **stability** and **throughput**. An organization doing well on these measures
seems to correlate with making more money, for example.

```bash
.
├── Stability
│  ├── Change Failure Rate
│  └── Recovery Failure Time
└── Throughput
   ├── Frequency of Deployments
   └── Lead Time
```

Stability is tracked by two metrics: the change failure rate, or how often a change introduces a defect,
and recovery failure time -- how long does it take to recover from a failure. In other words,
how often stuff breaks and stays broken.

Throughput can be distilled to two metrics as well: lead time, or how long does it take to get
from idea to working software, and frequency of deployments to production. These two metrics
track the speed that a team can ship code and the number of times it can iterate on ideas.

These measures should guide the selection of tools and help determine whether we're on the right track.

### Simplify

In addition to learning, Farley talks about managing complexity as the second core skill for a software engineer.
One look at a JavaScript app with its endless subfolders within `node_modules` brings this point home. There's way
more than any one person can keep in their working memory at any given time.

The dangers of complexity are also brought up by Jonathan Blow in his
brilliant talk from 2019, Preventing the Collapse of Civilization.

<YTPlayer url="https://www.youtube.com/watch?v=pW-SOdj4Kkk" />

The whole video is very much worth a watch, but in short, here are some consequences of growing complexity in software:

- Deep knowledge gets replaced by trivia
- A person can know a smaller percentage of what there is to know
- Good information gets drowned by noise.

The amount of complexity we can sustain over time is less than the amount of complexity a person can deal with at
a specific moment. There will be knowledge loss at each generational transfer, which leads to a decay in skills
needed to innovate and maybe even maintain existing systems, in the worst case leading to a loss of capability
for humankind, with many such precedents in history.

One solution could be to simplify at every level: hardware, operating systems, libraries, application code,
network, compilers, debuggers, distribution, user interfaces. Luckily there are also tools and techniques that help
with the goal of managing complexity, such as modularity, abstraction and separation of concerns.

However, there's also a difference between simplifying and building more layers of abstraction. The latter simply hides
complexity and can in fact add to it. Working on higher levels of abstraction may be justified and necessary in order
to give more people a chance to leverage code, but it's a useful conceptual difference to make.
Lest we all become dependent on low-code tools, without proper understanding of their inner workings.

### Creative precision

I consider myself a craftsman, in the sense that things I make are mostly unique. Not
particularly valuable, just imperfect in varying ways.

I can cook, but I wouldn't trust myself to feed more than a few dozen people. Similarly,
I can whip up a working web app, but probably not write code that'll land a spacecraft
on the moon safely every time.

What's missing here is precision and scalability. Sometimes I get it right, sometimes I won't.
That doesn't seem like engineering.

There may be an idea of a recipe or an experience, some mise en place, some stuff made from scratch,
some familiar techniques and less familiar patterns. There's a beauty to home cooking.

It's just not a particularly suitable approach to creating durable software that minimizes
complexity and can be worked on by many people simultaneously and smoothly.

Yet there's also a need to maintain a creative approach while building software. Often we have no clue
what our users want -- and they don't either. It's best to assume we won't get the design right
the first time, or catch all the bugs and think of all the edge cases.

Thus mitigating the cost of mistakes and working in iterative steps should be a priority.
That's also a very practical way of learning.

### Opposite of a good idea

This kind of iterative, creative approach reminded me of a non-technical writer I've enjoyed:
Rory Sutherland, who made his career in advertising. Sutherland talks about the perils of trying to
make sense of everything with verbalized logic. Sometimes our rationalizations have nothing to do with
the real reasons we act a certain way.

> Logic may be a good way to defend and explain a decision,
> but it is not always a good way to arrive at one.

<small>
  Rory Sutherland, [Alchemy](https://www.harperacademic.com/book/9780062388421/alchemy/)
</small>

The opposite of a good idea can also be a good idea, he says. If it's cheap and easy to
test that out in your application, why not do it?

It's possible to judge whether something works before understanding
why it works. One may stumble upon useful insights when unburdened by rigid plans,
particularly when people are involved. A good guess that stands up to empirical observation
can be a scientific breakthrough.

There's also the question of whether an engineer is simply expected to complete assigned tickets,
or leverage one's coding skills more broadly, solving problems and making decisions directly impacting
the business itself. I would think it's much more interesting to be a creative problem solver than a factory worker,
and it's likely to be better [compensated](https://blog.pragmaticengineer.com/what-silicon-valley-gets-right-on-software-engineers/).

Staying true to the iterative, creative learning process of developing software,
yet setting clear standards and measuring them. That seems like a worthy goal:
reproducible magic.
